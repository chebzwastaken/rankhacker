{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install seaborn\n",
    "%pip install numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing basic packages we need for graphing, we will import the data from the csv file. We will use the pandas library to do this. We will also use the matplotlib library to graph the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# data for red wine and white wine. \n",
    "red_wine = pd.read_csv(\"./winequality-red.csv\", sep=\";\")\n",
    "white_wine = pd.read_csv(\"./winequality-white.csv\", sep=\";\")\n",
    "\n",
    "# remove any empty rows\n",
    "red_wine = red_wine.dropna()\n",
    "white_wine = white_wine.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have worked so now we can graph the data showing wine quality distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot white wine quality distribution \n",
    "sns.countplot(x=\"quality\", data=red_wine)\n",
    "print(red_wine[\"quality\"].describe()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"quality\", data=white_wine)\n",
    "# describe white wine quality\n",
    "print(white_wine[\"quality\"].describe())\n",
    "print(white_wine[\"quality\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the data is normally distributed. We can also see that the average quality is `5.8` for the white wine and `5.6` for the red wine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pandas library we can create a new column called `alcohol_category` and assign the values to it.\n",
    "\n",
    "We are going use the `25th`, `50th` and `75th` percentile as low, medium and high respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(red_wine[\"alcohol\"].describe())\n",
    "\n",
    "# 3-valued alcohol category\n",
    "red_wine[\"alcohol_category\"] = pd.cut(red_wine[\"alcohol\"], \n",
    "                                      bins=[\n",
    "                                        red_wine[\"alcohol\"].min()-1,\n",
    "                                        red_wine[\"alcohol\"].quantile(0.25),\n",
    "                                        red_wine[\"alcohol\"].quantile(0.75),\n",
    "                                        red_wine[\"alcohol\"].max()\n",
    "                                            ], \n",
    "                                      labels=[\"low\", \"medium\", \"high\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason It would ignore the minimum value so i added - 1 to the minimum value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(white_wine[\"alcohol\"].describe())\n",
    "\n",
    "# 3-valued alcohol category\n",
    "# low: low < 0.25\n",
    "# medium: mean - std <= medium < mean + std\n",
    "# high: high >= mean + std\n",
    "\n",
    "white_wine[\"alcohol_category\"] = pd.cut(white_wine[\"alcohol\"],\n",
    "                                        bins=[\n",
    "                                            white_wine[\"alcohol\"].min()-1,\n",
    "                                            white_wine[\"alcohol\"].quantile(0.25),\n",
    "                                            white_wine[\"alcohol\"].quantile(0.75),\n",
    "                                            white_wine[\"alcohol\"].max()\n",
    "                                        ], \n",
    "                                        labels=[\"low\", \"medium\", \"high\"])\n",
    "\n",
    "\n",
    "white_wine[\"alcohol_category\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Describe the distribution of the quality of the wine for each alcohol category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare low, medium, high alcohol category\n",
    "sns.countplot(x=\"alcohol_category\", data=red_wine, hue=\"quality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low alcohol category has the highest number of wines with quality `5` and `6` with the lowest number of wines with quality `8`. \n",
    "The quality is normally distributed for the low alcohol category, with the average quality being `5.4`. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium alcohol category has the highest number of wines with quality `5` and `6`, with the lowest number of wines with quality `3` and `8` with the average quality being `5.7`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest quality in red wine is a `6`, with `7` not far behind. with the lowest qaulity being a `4` compared to low and medium categories where the lowest quality is a `3`. \n",
    "\n",
    "It seems that their is a positive correlation between alcohol content and quality, despite high alcogol red wine being the second highest count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"alcohol_category\", data=white_wine, hue=\"quality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low alcohol for white wine has the highest number of wines with quality `5` and `6` with the lowest number of wines with quality `9`, this was suprising since comparing it to red wine, the highest rating was an `8`. The average quality is `5.6`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium alcohol for white wine has the highest number of wines with quality `6`,  with the lowest number of wines with quality `3`. The average quality is `6`. It may be a better earlier to state this but it seems that users rate white wine higher than red wine as people who tend to enjoy it less are in the minority."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High alcohol for white wine has the highest number of wines with quality `6` and `7`, with the lowest number of wines with quality `3`. The average quality is `6.4`.\n",
    "From looking at the trend it seems that not only do people rate white wine higher than red wine, but they also rate it higher when the alcohol content is higher. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D) Plot residual sugar variable and identify suitable threshold for classifying wines as sweet or dry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual sugar distribution for both red wine\n",
    "sns.histplot(x=\"residual sugar\", data=red_wine, kde=True)\n",
    "\n",
    "print(red_wine[\"residual sugar\"].describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean is `2.5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual sugar distribution for both red wine\n",
    "sns.histplot(x=\"residual sugar\", data=white_wine, kde=True)\n",
    "\n",
    "print(white_wine[\"residual sugar\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine[\"type\"] = \"r\"\n",
    "white_wine[\"type\"] = \"w\"\n",
    "\n",
    "wine = pd.concat([red_wine, white_wine], ignore_index=True)\n",
    "wine.head()\n",
    "\n",
    "sns.displot(x=\"residual sugar\", data=wine, hue=\"type\")\n",
    "# mean \n",
    "wine[\"residual sugar\"].mean()\n",
    "\n",
    "# percentile formula \n",
    "def find_percentile(data, mean):\n",
    "    # number of values less than or equal to mean / total number of values\n",
    "    return (data[data <= mean].count() / data.count()) * 100 \n",
    "\n",
    "print(\"wine residual sugar percentile:\", find_percentile(wine[\"residual sugar\"], wine[\"residual sugar\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine[\"isSweet\"] = wine[\"residual sugar\"] > wine[\"residual sugar\"].quantile(0.62)\n",
    "print(wine[\"isSweet\"].value_counts())\n",
    "wine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the residual sugar one red wine, the mean is `2.5` and the median is `2.2`. \n",
    "\n",
    "When looking at the residual sugar one white wine, the mean is `6.4` and the median is `5.2`, although std is `5.1` which is quite high showing that the data is not normally distributed.\n",
    "\n",
    "When looking at sugar in wine chart [here](https://winefolly.com/deep-dive/sugar-in-wine-chart/) it seems that the threshold is around `6cal`. If I was to put the threshold at `6` the records would not totally be evenly split, when looking at the threshold, it seems that the total wine residual sugar content value around `5.4` is the best threshold for classifying wines as sweet or dry and is still \"close\" to the threshold of the official source."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have worked so now we can graph the data showing wine quality distribution. It's not perfectly even but it's close enough, and it's a good threshold for classifying wines as sweet or dry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quality vs isSweet\n",
    "sns.countplot(x=\"quality\", hue=\"isSweet\", data=wine)\n",
    "# print wine quality count isSweat \n",
    "print(wine.groupby([\"quality\", \"isSweet\"]).size())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data we can see that when looking at lower quaity wines, a greater number of dry wines are present compared to sweet wines. However, when looking at higher quality wines the number of sweet wines is increase, despite their being more dry wines. \n",
    "\n",
    "But this does show that the higher the quality of the wine, the more likely it is to be sweet, as there is a greater percentage of sweet wines in the higher quality wines compared to the lower quality wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alcohol_cat\n",
    "sns.countplot(x=\"quality\", hue=\"alcohol_category\", data=wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze correlation between quality and features\n",
    "wine.corr(\n",
    "    method=\"pearson\"\n",
    ")[\"quality\"].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the correlation between the quality and other variables, it seems that the quality is positively correlated with alcohol content, and negatively correlated with residual sugar content. But it seems that sulphates, citric acid, free sulfur dioxide and pH have some correlation with quality although it is not as strong as the other two; this could be due to the fact that the correlation is not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "sns.heatmap(wine.corr()[wine.corr() > 0.1], annot=True, vmin=0, vmax=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix shows a lot of useful correlations between the varaibles, ignoring correlation values lower than 0.1, as anthing lower is not considered a strong correlation.\n",
    "\n",
    "I immediately noticed a high correlation between residual sugar and isSweet, but that makes sense since the isSweet variable is based on the residual sugar variable. Furthermore, the correlation between density and residual sugar is also high, density also shows a positve correlation with fixed acidity.\n",
    "\n",
    "Second highest was between total sulfur dioxide and free sulfur dioxide, which makes sense since they are both related. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(wine.corr()[wine.corr() < 0], annot=True, vmin=-1, vmax=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at negative correlations, the highest was between alcohol and density, which makes sense since alcohol is a liquid and density is a measure of mass per unit volume.The second highest was between alcohol and residual sugar.\n",
    "\n",
    "I find these negative correlations interesting because they show that the higher the alcohol content, the lower the density and the lower the residual sugar content.\n",
    "\n",
    "Showing we can predict the quality of the wine based on the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify wine quality into 3 categories\n",
    "\n",
    "# low: <6\n",
    "# high: >=6\n",
    "print(wine[\"quality\"].describe())\n",
    "\n",
    "wine[\"quality_category\"] = wine[\"quality\"].apply(lambda x: \"low\" if x < 6 else \"high\")\n",
    "\n",
    "wine[\"quality_category\"].value_counts()\n",
    "wine.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split quality into two categories: low and high. Anything higher or equal to 6 is high quality, anything lower is low quality,\n",
    "When chaning the threshold it greatly affects the accuracy of the model. e.g when changing the threshold to 5 the accuracy woud go up to 97% but have low auc and macro average, but suprisingly, when changing the threshold to a 7 the accuracy not only increases but I get marco averages too although i get low auc and roc curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train, test = train_test_split(wine, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"train:\", train.shape)\n",
    "print(\"test:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"fixed acidity\",\n",
    "    \"volatile acidity\",\n",
    "    \"citric acid\",\n",
    "    \"residual sugar\",\n",
    "    \"chlorides\",\n",
    "    \"free sulfur dioxide\",\n",
    "    \"total sulfur dioxide\",\n",
    "    \"density\",\n",
    "    \"pH\",\n",
    "    \"sulphates\",\n",
    "    \"alcohol\",\n",
    "    \"alcohol_category\",\n",
    "    \"isSweet\"\n",
    "]\n",
    "\n",
    "train[\"alcohol_category\"] = train[\"alcohol_category\"].map({\"low\": 0, \"medium\": 1, \"high\": 2})\n",
    "train[\"isSweet\"] = train[\"isSweet\"].map({False: 0, True: 1})\n",
    "train[\"quality_category\"] = train[\"quality_category\"].map({\"low\": 0, \"high\": 1})\n",
    "\n",
    "test[\"alcohol_category\"] = test[\"alcohol_category\"].map({\"low\": 0, \"medium\": 1, \"high\": 2})\n",
    "test[\"isSweet\"] = test[\"isSweet\"].map({False: 0, True: 1})\n",
    "test[\"quality_category\"] = test[\"quality_category\"].map({\"low\": 0, \"high\": 1})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have split the data into training and testing data, I can use the training data to train the model and the testing data to test the model. \n",
    "\n",
    "One problem I had was attemping to use the `train_test_split` function from the `sklearn` library, but I kept getting an error saying that the data was not in the correct format. I tried to fix it by converting them into integers so instead of \"low\" and \"high\", it would be `0` and `1`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def k_fold_cross_validation(model, X, y, k=10):\n",
    "    kfold = KFold(n_splits=k, shuffle=False)\n",
    "    scores = cross_val_score(model, X, y, cv=kfold)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rf.fit(train[features], train[\"quality_category\"])\n",
    "k_fold_cross_validation(rf, train[features], train[\"quality_category\"])\n",
    "\n",
    "rf_predictions = rf.predict(test[features])\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(test[\"quality_category\"], rf_predictions, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the random forest classifier and evaluating the model using k-fold cross validation, I got an accuracy of `0.83` which is pretty good. Now I can run metrics on the model to see how well it performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=5000)\n",
    "k_fold_cross_validation(lr, train[features], train[\"quality_category\"])\n",
    "lr.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "lr_predictions = lr.predict(test[features])\n",
    "print(\"Logistic Regression\")\n",
    "print(classification_report(test[\"quality_category\"], lr_predictions, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using logistic regression we were able to get an accuracy of about `0.75`, which is not as good as the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "k_fold_cross_validation(dt, train[features], train[\"quality_category\"])\n",
    "dt.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "dt_predictions = dt.predict(test[features])\n",
    "print(\"Decision Tree\")\n",
    "print(classification_report(test[\"quality_category\"], dt_predictions, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree classifier gave us an accuracy of `0.77` which is not as good as the random forest classifier, but better than logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "k_fold_cross_validation(svm, train[features], train[\"quality_category\"])\n",
    "svm.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "svm_predictions = svm.predict(test[features])\n",
    "print(\"SVM\")\n",
    "print(classification_report(test[\"quality_category\"], svm_predictions, zero_division=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite possiblly the worst model, but it's still better than random guessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svm = SVC(C=1, kernel=\"linear\")\n",
    "k_fold_cross_validation(linear_svm, train[features], train[\"quality_category\"])\n",
    "linear_svm.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "linear_svm_predictions = linear_svm.predict(test[features])\n",
    "print(\"Linear SVM\")\n",
    "print(classification_report(test[\"quality_category\"], linear_svm_predictions, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did not expect a massive difference between the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = 'poly'\n",
    "degree = 3\n",
    "C = 5\n",
    "coef0 = 1\n",
    "\n",
    "poly_svm = SVC(C=C, kernel=kernel, degree=degree, coef0=coef0)\n",
    "k_fold_cross_validation(poly_svm, train[features], train[\"quality_category\"])\n",
    "poly_svm.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "poly_svm_predictions = poly_svm.predict(test[features])\n",
    "print(\"Polynomial SVM\")\n",
    "print(classification_report(test[\"quality_category\"], poly_svm_predictions, zero_division=0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using poly kernel, we were able to get an accuracy of `0.71` which is less than the previous model but I am not sure how to manipulate `degree`, `C`, `coetf0` to get a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = \"rbf\"\n",
    "\n",
    "rbf_svm = SVC(kernel=kernel, degree=degree, C=C, coef0=coef0)\n",
    "k_fold_cross_validation(rbf_svm, train[features], train[\"quality_category\"])\n",
    "rbf_svm.fit(train[features], train[\"quality_category\"])\n",
    "\n",
    "rbf_svm_predictions = rbf_svm.predict(test[features])\n",
    "print(\"RBF SVM\")\n",
    "print(classification_report(test[\"quality_category\"], rbf_svm_predictions, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc_curve(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(\"AUC for \" + model_name + \": \" + str(roc_auc))\n",
    "    plt.title('ROC - ' + model_name)\n",
    "    plt.plot(fpr, tpr, 'b', label='AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "# best model \n",
    "plot_roc_curve(test[\"quality_category\"], rf_predictions, \"Random Forest\")\n",
    "plot_roc_curve(test[\"quality_category\"], lr_predictions, \"Logistic Regression\")\n",
    "plot_roc_curve(test[\"quality_category\"], dt_predictions, \"Decision Tree\")\n",
    "# best model for svm\n",
    "plot_roc_curve(test[\"quality_category\"], linear_svm_predictions, \"SVM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest Area Under the Curve (AUC) was for the random forest classifier, which is not suprising since it had the highest accuracy and the opposite for the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# logistic regression\n",
    "print(\"Logistic Regression\")\n",
    "print(\"MSE:\", mean_squared_error(test[\"quality_category\"], lr_predictions))\n",
    "\n",
    "# SVM\n",
    "print(\"Support Vector Machine\")\n",
    "print(\"MSE:\", mean_squared_error(test[\"quality_category\"], svm_predictions))\n",
    "print(\"MSE:\", mean_squared_error(test[\"quality_category\"], linear_svm_predictions))\n",
    "print(\"Polynomial SVM\")\n",
    "print(\"MSE:\", mean_squared_error(test[\"quality_category\"], poly_svm_predictions))\n",
    "print(\"RBF SVM\")\n",
    "print(\"MSE:\", mean_squared_error(test[\"quality_category\"], rbf_svm_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of low and high, we can use the actual quality score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(train[features], train[\"quality\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of finding the best combination of hyperparameters for a model.\n",
    "\n",
    "This took about 2 hours to run, and I was not able to get the best parameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, max_depth=30, max_features='sqrt', min_samples_leaf=1, min_samples_split=2, n_estimators=600)\n",
    "\n",
    "k_fold_cross_validation(rf, train[features], train[\"quality\"])\n",
    "rf.fit(train[features], train[\"quality\"])\n",
    "\n",
    "rf_predictions = rf.predict(test[features])\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(classification_report(test[\"quality\"], rf_predictions, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
